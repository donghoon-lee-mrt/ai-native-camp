# Session 2: day1 2번째 과제를 해보자.

- **Session ID**: `76fca770-fbf8-4d86-a316-235465c28bbd`
- **시작 시각**: 2026-02-16 08:34 KST
- **메시지 수**: 22

---

### User (08:34:15)

day1 2번째 과제를 해보자.

---

### Assistant (08:34:20)

프로젝트 구조를 먼저 살펴볼게요.

---

### Assistant (08:34:20)

[Tool: Bash → `List project root directory`]

---

### Assistant (08:34:23)

[Tool: Bash → `List day1 directory recursively`]

---

### Assistant (08:34:24)

[Tool: Bash → `List references directory recursively`]

---

### Assistant (08:34:26)

[Tool: Read → /Users/donghoon-lee/Working/2026/02/16/ai-native-camp/day1/HOMEWORKS.md]

---

### Assistant (08:34:27)

[Tool: Read → /Users/donghoon-lee/Working/2026/02/16/ai-native-camp/references/SELF_INTRODUCTION.md]

---

### Assistant (08:34:52)

숙제 2는 **"1주일 과제에 대해 Claude에게 3번 질문하기"**네요. 그리고 토론을 하자고 하셨으니, 바로 시작하죠.

동훈님의 1주일 과제는 **사내 AI Native Workshop 프로그램 수립**이고, 핵심 문제의식은 이렇게 정리됩니다:

> 구성원들이 AI에게 1차원적 질문만 하고, 한 번 실패하면 포기한다. 원인은 관련 개념 부재 + AI 동작 원리 미이해 → 질문을 풍부하게 못 만듦.

여기에 대해 제 관점을 먼저 던져볼게요.

---

**제가 의문을 갖는 지점**: "개념 체계를 잡아주면 질문이 풍부해진다"는 가설이 맞는지.

제 반론은 이렇습니다:

1. **개념을 안다고 행동이 바뀌진 않는다.** 교육에서 가장 흔한 함정이 "알면 할 수 있다"는 가정이에요. 컨텍스트 개념을 이해해도, 실무에서 "아 이건 컨텍스트를 더 줘야 하는 상황이구나"라고 인식하는 건 별개의 능력이거든요.

2. **진짜 병목은 '실패 후 전략 전환'이 아니라 '성공 경험 부재'일 수 있다.** 한 번도 AI로 "와, 이게 되네?"를 경험하지 못한 사람은 개념을 알아도 동기 자체가 없어요. 

3. **비개발자에게 "에이전트 동작 방식"을 가르치는 게 오히려 역효과일 수 있다.** 너무 기술적으로 접근하면 "역시 어려운 거구나"라는 인식만 강화될 수도 있거든요.

---

그래서 제가 던지고 싶은 질문은:

**Workshop의 진짜 목표가 "개념 교육"이어야 하는지, 아니면 "성공 체험 설계"여야 하는지?** 

동훈님은 어떻게 생각하세요? 이 두 가지가 어떤 비중으로 섞여야 한다고 보시는지, 아니면 제 반론에 동의하지 않는 부분이 있는지 이야기해주세요.

---

### User (08:35:44)

성공 체험 설계인게 너무 당연히 좋지. 물론 참석하려는 사람들도 해결하려는 문제가 있는 것이 좋고.

---

### Assistant (08:36:03)

동의하는데, 바로 다음 문제가 생기죠.

**"해결하려는 문제가 있는 사람"을 전제로 하면, Workshop 대상이 극도로 좁아진다.**

현실적으로 사내 Workshop 참가자를 생각해보면 세 부류가 있을 거예요:

1. **문제가 명확한 사람** — "매주 리포트 만드는 데 3시간 걸리는데 줄이고 싶다" → 이 사람은 Workshop 없어도 잘 할 가능성이 높음
2. **막연히 관심 있는 사람** — "AI 잘 쓰고 싶긴 한데 뭘 해야 할지 모르겠다" → 다수. 문제 정의 자체를 못 함
3. **떠밀려 온 사람** — "팀장이 가라고 했다" → 무시 못 하는 현실

동훈님이 작년에 1:1 멘토 형식으로 했을 때를 떠올려보면, 실제로 효과가 좋았던 사람은 몇 번 유형이었어요?

제 가설은 이래요: **1번은 멘토링만으로 충분하고, 3번은 뭘 해도 어렵고, Workshop의 진짜 타겟은 2번이다.** 그런데 2번에게 "해결할 문제를 가져오라"고 하면 이미 첫 번째 허들에서 탈락해요.

그러면 설계 방향이 갈리는데:

- **A안**: 참가자의 실제 업무에서 문제를 같이 발굴해주는 것부터 Workshop에 포함
- **B안**: 범용적이지만 "와 이게 되네?" 할 만한 시나리오를 우리가 미리 설계해서 제공

어느 쪽이 더 현실적이라고 보세요? 아니면 아예 다른 접근이 있을까요?

---

### User (08:36:31)

근데 개념 교육도 필요할 것 같아. 성공 체험 설계를 하더라도 그 와중에 이해되지 않는 용어들이나 개념에 대한 설명은 곁들ㅇ여야 하니까. 이걸 본 교육에 모두 녹여버리면 비효율이 발생할 수 있으니, 복습 혹은 추가 학습할 수 있는 자료는 있으면 좋을 것 같아.

---

### Assistant (08:36:51)

좋은 구분이에요. 정리하면 이런 구조가 되는 거죠:

- **본 교육**: 성공 체험 중심, 개념은 맥락 안에서 최소한으로
- **보조 자료**: 용어/개념 레퍼런스, 자기 페이스로 복습

근데 여기서 하나 도전해볼게요.

**"보조 자료"가 실제로 읽힐까?**

경험적으로 사내 교육 후 보조 자료를 자발적으로 복습하는 비율은 거의 없잖아요. 특히 2번 유형(막연히 관심 있는 사람)은 더더욱. 그러면 두 가지 선택지가 있는데:

**1. 보조 자료를 "읽을 자료"가 아니라 "찾아볼 자료"로 설계한다**
- 글로서리 형태. Workshop 중에 "이거 뭐지?" 싶을 때 바로 찾아보는 용도
- 사후 복습용이 아니라 실시간 참조용

**2. 개념 학습 자체를 AI와의 대화로 해결한다**
- "프롬프트가 뭔지 모르겠으면 Claude한테 물어봐라"
- Workshop의 첫 번째 성공 체험이 "AI에게 AI 개념을 물어보는 것" 자체가 됨
- 자료를 우리가 만들 필요 없이, "질문하는 법"만 가르치면 됨

2번이 좀 메타적이긴 한데, 동훈님 문제의식과 맞닿아 있어요. "질문을 풍부하게 못 한다"가 근본 원인이라고 했잖아요. 그러면 개념 자료를 떠먹여주는 게 아니라, **모르는 걸 AI한테 물어보는 경험 자체가 첫 번째 훈련**이 되는 거죠.

이러면 Workshop 흐름이:
1. 모르는 개념 → AI에게 물어보기 (성공 체험 #1: "이것도 설명해주네?")
2. 실제 업무 문제 → AI와 같이 풀기 (성공 체험 #2: "이걸 이렇게 해결하네?")

이런 식으로 자연스럽게 이어질 수 있는데, 이 방향에 대해 어떻게 생각하세요?

---

### User (08:37:49)

2번이 여러모로 좋을것 같긴 하네. 내가 뭘 만들 필요도 없고 말야. 접근성만 좋다면!

---

### Assistant (08:38:06)

맞아요, 그런데 "접근성만 좋다면"이 사실 핵심 허들이에요.

비개발자가 AI한테 AI 개념을 물어보려면, **최소한 AI와 대화를 시작할 수 있어야** 하잖아요. 근데 현실은:

- ChatGPT/Claude 계정이 없는 사람도 있고
- 있어도 회사 보안 정책상 업무 데이터 입력이 꺼려지고
- "빈 입력창"을 보면 뭘 쳐야 할지 자체를 모름

세 번째가 제일 치명적이에요. **빈 입력창 공포증**. 검색엔진은 키워드만 넣으면 되지만, AI 대화창은 "뭘 어떻게 말해야 하지?"부터 막히거든요.

그래서 접근성을 높이려면 두 가지가 필요할 것 같은데:

**인프라 측면**: 회사에서 공식적으로 쓸 수 있는 AI 채널 세팅 (이건 마이리얼트립에 이미 있나요?)

**UX 측면**: 빈 입력창이 아니라, 첫 마디를 던져주는 장치
- 예: "아래 문장을 그대로 복붙해서 시작해보세요" 같은 시작 가이드
- 또는 Workshop 중에 퍼실리테이터가 "자, 이거 그대로 쳐보세요" 하고 라이브로 같이 하기

솔직히 후자가 Workshop이 해줄 수 있는 가장 큰 역할 아닌가 싶어요. **혼자서는 못 치는 첫 번째 엔터를, 옆에서 같이 쳐주는 것.** 

마이리얼트립 내부에 AI 접근 인프라는 어느 정도 갖춰져 있어요?

---

### User (08:39:47)

회사에서 공식적으로 쓰는 AI 슬랙 채널이 있지~ 슬랙 통합이 좋을거 같아. 그럼 다른사람들이 하는 질문도 볼 수 있잖아? 슬랙에서는 첫 마디를 던져줄 수는 없는데, 다른사람들의 질문을 보면 도움이 되지 않을까? 싶기도 하고

---

### Assistant (08:40:05)

오, 슬랙 통합이면 접근성 문제가 거의 해결되네요. 매일 쓰는 도구니까.

그리고 **다른 사람 질문이 보인다**는 게 생각보다 강력한 포인트예요. 이게 왜 좋냐면:

**빈 입력창 공포증의 진짜 해결책은 "남이 하는 걸 보는 것"이거든요.**

자료를 읽는 것보다, "아 저 사람은 저렇게 물어보네?" 하고 보는 게 훨씬 빠르게 체화돼요. 일종의 사회적 학습이죠. 그리고 심리적 안전감도 생기고 — "저 사람도 이런 기초적인 걸 물어보네, 나도 물어봐도 되겠다."

근데 여기서 한 가지 우려가 있어요.

**슬랙 AI 채널이 이미 있다면, 지금도 잘 쓰이고 있어야 하는 거 아닌가요?** 채널이 있는데도 구성원들이 1차원적 질문에 그치고 포기한다는 거면, 채널 존재만으로는 부족하다는 뜻이잖아요.

그러면 Workshop이 해줘야 할 역할이 좀 더 구체화되는데:

- 채널이라는 **인프라는 이미 있다**
- 부족한 건 **"첫 질문을 던지게 만드는 트리거"와 "질문의 질을 높이는 피드백 루프"**

Workshop에서 할 일이 결국 이 두 가지로 수렴하는 것 같은데요:

1. **라이브로 같이 질문 던져보기** — "자, 지금 슬랙 채널 열고, 이 질문 그대로 쳐보세요"
2. **좋은 질문 vs 아쉬운 질문을 비교해서 보여주기** — 기존 채널 히스토리에서 실제 사례를 뽑아서

기존 슬랙 채널에 쌓인 질문들을 보면, 실제로 질문 수준의 편차가 큰 편이에요? 아니면 질문 자체가 별로 안 올라오는 상황인가요?

---

### User (08:41:26)

기존 슬랙 채널은 개념 질문보다는 주로 어떤 요청들이 들어오는 편이지. 근데 그 요청들이 앞뒤가 안 맞는 경우도 종종 있거든. 그럴때는 개념정리가 도움 될 때가 있어. 스레드 안에서 설명해주는 일이 꽤 있지.

---

### Assistant (08:41:46)

아, 그러면 현장감 있는 그림이 그려지네요.

**이미 일어나고 있는 일이 있다는 거잖아요:**
- 요청이 들어온다 → 앞뒤가 안 맞는다 → 스레드에서 동훈님이 개념을 설명해준다 → 그제서야 질문이 정리된다

이거 사실상 **1:1 멘토링이 슬랙에서 비공식적으로 반복**되고 있는 거예요. 그리고 그 병목이 동훈님한테 집중되고 있고.

그러면 Workshop의 목표가 하나 더 선명해지는데:

**"동훈님이 스레드에서 반복적으로 하고 있는 일을 확장 가능하게 만드는 것"**

지금 구조의 문제:
- 동훈님이 설명 → 그 사람만 배움 → 다른 사람은 같은 실수 반복
- 스레드 안에 묻혀서 다른 사람이 안 봄

이걸 Workshop 없이도 해결하는 방법이 하나 떠오르는데요.

**기존 슬랙 채널에서 자주 반복되는 "앞뒤 안 맞는 패턴"을 모아서, "이런 요청을 하기 전에 이것부터 정리해보세요" 같은 가이드를 채널 상단에 고정**해두는 것. 이건 자료를 새로 만드는 게 아니라, 이미 동훈님이 스레드에서 했던 설명을 재활용하는 거라 부담도 적고.

근데 이것만으로는 부족하고, Workshop과 결합하면 이런 흐름이 가능해요:

1. **Workshop 전**: 슬랙 채널의 실제 "앞뒤 안 맞는 사례" 수집
2. **Workshop 본편**: 그 사례를 같이 보면서 "이 요청이 왜 안 먹히는지, 어떻게 고치면 되는지" 라이브로 고쳐보기
3. **Workshop 후**: 채널에서 비슷한 패턴이 보이면 참가자끼리 피드백하는 문화

이러면 교육 콘텐츠를 따로 만들 필요 없이, **실제 슬랙 히스토리가 곧 교재**가 되는 거죠.

이 방향이면 "앞뒤 안 맞는 요청"의 대표적인 패턴이 뭔지가 중요한데, 자주 보이는 유형 몇 가지 공유해줄 수 있어요?

---

### User (08:43:56)

(우리 근데 이 토론의 목적이 뭐야? 언제 끝나는거야...)
유형을 지금은 분석하지 말자고. 차라리 유형 분석과 그걸 기반으로 답변해 주는 슬랙에서 활동하는 AI Agent 를 만들어보는건 어때? 이것도 일주일 안에 풀어볼만한 미션이 될 수 있겠구만

---

### Assistant (08:44:13)

하하, 맞아요. 토론이 발산하고 있었네요. 정리하죠.

**이 토론의 목적은 숙제 2** — 1주일 과제에 대해 3번 질문하고, 가장 좋은 Q&A 하나를 공유하는 것.

지금까지 토론에서 나온 핵심 결론을 정리하면:

1. Workshop은 개념 교육이 아니라 **성공 체험 설계**
2. 개념 학습은 **AI에게 AI를 물어보는 것** 자체로 해결
3. 인프라는 **기존 슬랙 채널** 활용
4. 교재는 **실제 슬랙 히스토리**에서 추출
5. 그리고 방금 나온 — **유형 분석 + 응대하는 슬랙 AI Agent**를 직접 만드는 것

5번이 꽤 좋은데요. Workshop 프로그램 "수립"에 그치지 않고, **실제로 동작하는 산출물**이 나오니까. 동훈님 스타일("이론보다 실행, 빠르게 만들고 증명한다")에도 딱 맞고.

---

그러면 이제 남은 질문 횟수를 써볼까요? 지금까지 큰 방향성 토론을 했으니, 나머지 질문은 구체적으로 가는 게 좋을 것 같아요. 예를 들면:

- 슬랙 AI Agent의 구체적인 스펙/동작 방식
- 1주일 안에 만들기 위한 MVP 범위
- Workshop과 Agent를 결합한 전체 프로그램 구조

어떤 방향으로 질문해볼래요?

---

### User (08:47:24)

질문 횟수는 중요하지 않으니, 우리 이번 1주일 캠프에서 풀고자 하는 문제만 뾰족하게 만들자.

---

### Assistant (08:47:36)

좋아요. 지금까지 나온 걸 압축하면:

**현상**: 슬랙 AI 채널에 앞뒤 안 맞는 요청이 들어옴 → 동훈님이 스레드에서 1:1로 개념 설명 → 그제서야 해결. 이게 반복되고, 확장이 안 됨.

**풀고 싶은 것**: 이 "동훈님이 스레드에서 하는 일"을 자동화/확장하는 것.

그러면 문제를 이렇게 세울 수 있는데:

> **"앞뒤 안 맞는 요청을 받았을 때, 부족한 맥락을 되물어주고 요청을 정리해주는 슬랙 AI Agent를 만든다"**

근데 이게 정말 뾰족한가? 한 번 찔러볼게요.

**이 Agent가 해결하는 게 "요청 품질"인지, "동훈님의 병목"인지** 분명히 해야 해요. 둘 다라고 하면 초점이 흐려지거든요.

- 요청 품질이 목표면 → Agent가 되물어서 요청을 정리해주는 데 집중
- 동훈님 병목이 목표면 → Agent가 직접 답변까지 해주는 데 집중

1주일이면 둘 다는 어려울 텐데, 어느 쪽이에요?

---
